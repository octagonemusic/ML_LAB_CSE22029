import numpy as np

def summation_unit(inputs, weights):
    """
    Calculate the weighted sum of inputs.
    
    :param inputs: List of input values
    :param weights: List of weights corresponding to the inputs
    :return: Weighted sum
    """
    return np.dot(inputs, weights)

def step_function(x):
    """
    Step activation function.
    
    :param x: Input value
    :return: 1 if x >= 0 else 0
    """
    return 1 if x >= 0 else 0

def bipolar_step_function(x):
    """
    Bipolar Step activation function.
    
    :param x: Input value
    :return: 1 if x >= 0 else -1
    """
    return 1 if x >= 0 else -1

def sigmoid_function(x):
    """
    Sigmoid activation function.
    
    :param x: Input value
    :return: Sigmoid of x
    """
    return 1 / (1 + np.exp(-x))

def tanh_function(x):
    """
    TanH activation function.
    
    :param x: Input value
    :return: TanH of x
    """
    return np.tanh(x)

def relu_function(x):
    """
    ReLU activation function.
    
    :param x: Input value
    :return: ReLU of x
    """
    return max(0, x)

def leaky_relu_function(x, alpha=0.01):
    """
    Leaky ReLU activation function.
    
    :param x: Input value
    :param alpha: Slope of the function for x < 0
    :return: Leaky ReLU of x
    """
    return x if x >= 0 else alpha * x

def error_calculation(actual_output, expected_output):
    """
    Comparator unit for error calculation.
    
    :param actual_output: The output generated by the model.
    :param expected_output: The expected output.
    :return: The difference between actual and expected output.
    """
    return expected_output - actual_output
